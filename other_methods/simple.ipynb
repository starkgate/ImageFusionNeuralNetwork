{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grosser Beleg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygeoa42M6dUB",
        "colab_type": "code",
        "outputId": "4481148a-38ec-44de-b176-42a40bc3ee46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        }
      },
      "source": [
        "# Install TensorFlow 2.0 for GPU\n",
        "!pip uninstall -y -q tensorflow\n",
        "!pip install -q tensorflow==2.0.0\n",
        "!pip install -q gast==0.2.2\n",
        "!pip install -q keract\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "import tensorflow as tf\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "print(tf.__version__)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 86.3MB 52kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 46.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 62.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.4MB/s \n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.11.0 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 378kB 5.1MB/s \n",
            "\u001b[?25h2.0.0\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTZFCuQRj-UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utilities.py\n",
        "from tensorflow.python.framework import constant_op, dtypes, ops\n",
        "from tensorflow.python.ops import array_ops, control_flow_ops, math_ops, nn, nn_ops\n",
        "import os\n",
        "\n",
        "import imageio\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as keras\n",
        "\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import ipywidgets\n",
        "from ipywidgets import interact\n",
        "\n",
        "base_path = \"/content/drive/My Drive/Colab Notebooks/\"\n",
        "# contains *.tif, *_MRI.nii, *_LABEL.nii, *_GT.png files\n",
        "path_training = base_path + \"training/\"\n",
        "path_testing = base_path + \"testing/\"\n",
        "path_groundtruth_training = base_path + \"groundtruth-training/\"\n",
        "path_groundtruth_testing = base_path + \"groundtruth-testing/\"\n",
        "\n",
        "# define parameters\n",
        "batch_size = 1\n",
        "epoch = 3\n",
        "lr = 0.002\n",
        "lamda = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc3p-KPRjk5w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def save_png(tensor, name):\n",
        "    img = tf.cast(img, tf.uint8)\n",
        "    img = tf.image.encode_png(img)\n",
        "    tf.io.write_file('pred/' + name, img)\n",
        "    return tensor\n",
        "\n",
        "def show_volume(volume):\n",
        "  show_information(volume)\n",
        "  a = tf.transpose(volume,(2,0,1))\n",
        "  def print_volume(x):\n",
        "    plt.imshow(a[x], cmap='jet')\n",
        "  interact(print_volume, x=ipywidgets.IntSlider(min=0, max=tf.shape(volume)[2]-1, step=1, value=0))\n",
        "\n",
        "def show_information(x):\n",
        "  tf.print(\"Tensor Shape:\", tf.shape(x))\n",
        "  tf.print(\"Shape:\", x.shape)\n",
        "  tf.print(\"Mean:\", tf.reduce_mean(x))\n",
        "  tf.print(\"Min:\", tf.reduce_min(x))\n",
        "  tf.print(\"Max:\", tf.reduce_max(x))\n",
        "\n",
        "@tf.function\n",
        "def normalize_dataset(tensor):\n",
        "    return tf.divide(\n",
        "       tf.subtract(\n",
        "          tensor,\n",
        "          tf.reduce_min(tensor)\n",
        "       ),\n",
        "       tf.subtract(\n",
        "          tf.reduce_max(tensor),\n",
        "          tf.reduce_min(tensor)\n",
        "       )\n",
        "    )\n",
        "  \n",
        "@tf.function\n",
        "def to_float_dataset(tensor):\n",
        "    return tf.cast(tensor, tf.float32)\n",
        "\n",
        "@tf.function\n",
        "def zero_to_one_dataset(tensor):\n",
        "    # int16 to float32, scaling from 0-32k to 0-1 is done automatically\n",
        "   return tf.image.convert_image_dtype(tensor, tf.float32)\n",
        "\n",
        "# loss function : 2 possibilities\n",
        "# SSIM on prediction vs NSST groundtruth\n",
        "# or SSIM on prediction vs each of the input slices\n",
        "# y_true is the input volume\n",
        "@tf.function\n",
        "def loss_ssim_unsupervised(y_true, y_pred):\n",
        "    #shape pred [1 240x 240y 1z]\n",
        "    #shape true [1 240x 240y 155z]\n",
        "    y_true = tf.transpose(y_true, perm=[3,1,2,0])\n",
        "    y_pred = tf.squeeze(y_pred, 0)\n",
        "    #reshape pred [240x 240y 1z]\n",
        "    #reshape true [155z 240x 240y 1]\n",
        "\n",
        "    def ssim_l1_loss(elems):\n",
        "        ssim_layer_loss = lamda * (1 - tf.image.ssim(elems, y_pred, max_val = 1.0))\n",
        "        l1_layer_loss = (1 - lamda) * (tf.reduce_mean(tf.abs(elems - y_pred)))\n",
        "        return ssim_layer_loss + l1_layer_loss\n",
        "\n",
        "    loss = tf.map_fn(ssim_l1_loss, y_true, dtype=tf.float32)\n",
        "    # sum of all (l1 + ssim) layer losses = total loss\n",
        "    return tf.reduce_sum(loss)\n",
        "    \n",
        "@tf.function\n",
        "def loss_binary_crossentropy_unsupervised(y_true, y_pred):\n",
        "    y_true = tf.transpose(y_true, perm=[3,1,2,0])\n",
        "    y_pred = tf.squeeze(y_pred, 0)\n",
        "\n",
        "    def binary_crossentropy_l1_loss(elems):\n",
        "        binary_crossentropy_layer_loss = lamda * (1 - tf.keras.backend.binary_crossentropy(elems, y_pred))\n",
        "        #l1_layer_loss = (1 - lamda) * (tf.reduce_mean(tf.abs(elems[0] - elems[1])))\n",
        "        return binary_crossentropy_layer_loss # + l1_layer_loss\n",
        "\n",
        "    loss = tf.map_fn(binary_crossentropy_l1_loss, y_true, dtype=tf.float32)\n",
        "    # sum of all (l1 + ssim) layer losses = total loss\n",
        "    return tf.reduce_sum(loss)\n",
        "\n",
        "# SSIM on prediction vs groundtruth\n",
        "# y_true is the NSST groundtruth\n",
        "@tf.function\n",
        "def loss_ssim_supervised_nsst(y_true, y_pred):\n",
        "    # ssim and l1 loss : compare NSST groundtruth to the network's prediction\n",
        "    ssim_mri_loss = lamda * (1 - tf.image.ssim(y_pred, y_true, max_val = 1.0))\n",
        "    l1_mri_loss = (1 - lamda) * (tf.reduce_mean(tf.abs(y_pred - y_true)))\n",
        "    return ssim_mri_loss + l1_mri_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kis6elJE2GF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"PREPARING DATASET\")\n",
        "# load the training files from img folder : 3D MRI, 3D label mask\n",
        "get_volume = lambda file: nib.load(file).get_data()\n",
        "get_image = lambda file: pyplot.imread(file)\n",
        "\n",
        "# 100 volumes, 100x240x240x155 voxels, values in 0-2^16/2, int16 array\n",
        "train_volumes_mri = np.array(list(map(get_volume, glob.glob(path_training + \"*_MRI.nii\"))))\n",
        "# 100 volumes, 100x240x240x155 voxels, values 0 or 1, uint8 array\n",
        "train_volumes_label = np.array(list(map(get_volume, glob.glob(path_training + \"*_LABEL.nii\"))))\n",
        "# 100 images, 100x240x240x1, values 0-2^16, uint16\n",
        "train_images_groundtruth = np.array(list(map(get_image, glob.glob(path_groundtruth_training + \"*.tif\"))))\n",
        "train_images_groundtruth = np.expand_dims(train_images_groundtruth, axis=-1) # empty dimension for channel\n",
        "print(\"Found training dataset\")\n",
        "\n",
        "# implicit cast to float32 tensor, values in 0-1\n",
        "# 3 options: normalize or divide by max integer value or cast to float\n",
        "#train_volumes_mri = tf.map_fn(zero_to_one_dataset, train_volumes_mri, dtype=tf.float32)\n",
        "train_volumes_mri = tf.map_fn(normalize_dataset, train_volumes_mri, dtype=tf.float32)\n",
        "#train_volumes_mri = tf.map_fn(to_float_dataset, train_volumes_mri, dtype=tf.float32)\n",
        "#train_images_groundtruth = tf.map_fn(zero_to_one_dataset, train_images_groundtruth, dtype=tf.float32)\n",
        "train_images_groundtruth = tf.map_fn(normalize_dataset, train_images_groundtruth, dtype=tf.float32)\n",
        "#train_images_groundtruth = tf.map_fn(to_float_dataset, train_images_groundtruth, dtype=tf.float32)\n",
        "print(\"Normalized training dataset\")\n",
        "\n",
        "# mask dataset to remove all irrelevant data\n",
        "# implicit cast label to bool tensor\n",
        "train_volumes_mri_mask = tf.not_equal(train_volumes_label, 0)\n",
        "# bool to 0 or 1\n",
        "train_volumes_mri_mask = tf.cast(train_volumes_mri_mask, tf.float32)\n",
        "# mask the MRI data with the label data, cast to int16 tensor\n",
        "train_volumes_mri = tf.multiply(train_volumes_mri, train_volumes_mri_mask)\n",
        "print(\"Masked training dataset\")\n",
        "\n",
        "test_volumes_mri = np.array(list(map(get_volume, glob.glob(path_testing + \"*_MRI.nii\"))))\n",
        "test_volumes_label = np.array(list(map(get_volume, glob.glob(path_testing + \"*_LABEL.nii\"))))\n",
        "test_images_groundtruth = np.array(list(map(get_image, glob.glob(path_groundtruth_testing + \"*.tif\"))))\n",
        "test_images_groundtruth = np.expand_dims(test_images_groundtruth, axis=-1)\n",
        "print(\"Found testing dataset\")\n",
        "\n",
        "# normalize the data\n",
        "#test_images_groundtruth = tf.map_fn(zero_to_one_dataset, test_images_groundtruth, dtype=tf.float32)\n",
        "test_images_groundtruth = tf.map_fn(normalize_dataset, test_images_groundtruth, dtype=tf.float32)\n",
        "#test_images_groundtruth = tf.map_fn(to_float_dataset, test_images_groundtruth, dtype=tf.float32)\n",
        "#test_volumes_mri = tf.map_fn(zero_to_one_dataset, test_volumes_mri, dtype=tf.float32)\n",
        "test_volumes_mri = tf.map_fn(normalize_dataset, test_volumes_mri, dtype=tf.float32)\n",
        "#test_volumes_mri = tf.map_fn(to_float_dataset, test_volumes_mri, dtype=tf.float32)\n",
        "print(\"Normalized testing dataset\")\n",
        "\n",
        "# mask the MRI data with the label data\n",
        "test_volumes_mri_mask = tf.not_equal(test_volumes_label, 0)\n",
        "test_volumes_mri_mask = tf.cast(test_volumes_mri_mask, tf.float32)\n",
        "test_volumes_mri = tf.multiply(test_volumes_mri, test_volumes_mri_mask)\n",
        "print(\"Masked testing dataset\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SdA5IUg_edR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the min and max coordinates where data can be found in a volume\n",
        "def crop_size(arr):\n",
        "  y, x = np.where(np.any(arr, 0))\n",
        "  z, _ = np.where(np.any(arr, 1))\n",
        "  minc = min(z),min(y),min(x)\n",
        "  maxc = max(z)+1,max(y)+1,max(x)+1\n",
        "  return minc,maxc # return cropped volume and coordinates\n",
        "\n",
        "# crop the volume and groundtruth according to a given size\n",
        "def crop(volume,size):\n",
        "  (minc,maxc) = size\n",
        "  return volume[minc[0]:maxc[0],minc[1]:maxc[1],minc[2]:maxc[2]]\n",
        "\n",
        "# pad the cropped volumes and groundtruth to match the optimal size\n",
        "def pad(volume,size):\n",
        "  (minc,maxc) = size\n",
        "  delta = np.subtract(opt, np.subtract(maxc, minc)) # optimal - current = how much padding should be added to the cropped volume\n",
        "  delta = np.divmod(delta, 2)\n",
        "  below = delta[0]; above = np.sum(delta, axis=0) # how much padding to add below and above\n",
        "  return np.pad(volume,np.transpose((below,above)).astype(int), mode='constant', constant_values=0)\n",
        "\n",
        "cropped_test_volumes_size = list(map(crop_size, test_volumes_mri))\n",
        "cropped_test_volumes = list(map(crop, test_volumes_mri,cropped_test_volumes_size))\n",
        "cropped_train_volumes_size = list(map(crop_size, train_volumes_mri))\n",
        "cropped_train_volumes = list(map(crop, train_volumes_mri,cropped_train_volumes_size))\n",
        "\n",
        "# get the delta between max and min\n",
        "cropped_volume_optimal_size = list(map(lambda x: (x[1]-x[0]),\n",
        "                               np.append(cropped_train_volumes_size, cropped_test_volumes_size, axis=0)))\n",
        "\n",
        "opt = np.amax(cropped_volume_optimal_size,axis=0) # get the highest delta\n",
        "opt = 2**np.ceil(np.log2(opt)) # pad to closest power of 2 for unet\n",
        "optx,opty,optz = opt\n",
        "\n",
        "cropped_padded_train_volumes_mri = list(map(pad,cropped_train_volumes,cropped_train_volumes_size))\n",
        "cropped_padded_test_volumes_mri = list(map(pad,cropped_test_volumes,cropped_test_volumes_size))\n",
        "cropped_padded_train_volumes_mri = tf.cast(cropped_padded_train_volumes_mri, tf.float32)\n",
        "cropped_padded_test_volumes_mri = tf.cast(cropped_padded_test_volumes_mri, tf.float32)\n",
        "\n",
        "#get size of cropped volume\n",
        "print(\"Cropped dataset\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8CoKr8lkdzt",
        "colab_type": "code",
        "outputId": "b75e8214-b28d-4421-a256-759c97181960",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 2D neural network :\n",
        "# transform 240 x 240 x 155 volume into 240 x 240 x 1 plane through successive 2D convolutions with decreasing filters (155 -> 128 -> 64 -> 32 -> 16 -> 1)\n",
        "# Initialize the weights based on truncated normal distribution with standard deviation of 0.01\n",
        "# Bias of 0. No downsampling.\n",
        "# Leaky ReLU activation to avoid banding\n",
        "\n",
        "# layer 1\n",
        "# input_shape = (samples, conv_dim1, conv_dim2, channels), with \"channels\" the depth of the volume\n",
        "# output_shape = (samples, new_conv_dim1, new_conv_dim2, filters)\n",
        "input = tf.keras.Input(shape=(240,240,155)) # 3D tensor with shape: (conv_dim1, conv_dim2, channels)\n",
        "network = tf.keras.layers.Conv2D(\n",
        "    filters = 128, # dimensionality of output space\n",
        "    kernel_size = 5, # shape of 2D convolution window (5x5)\n",
        "    strides = 1, # stride of convolution along all spatial dimensions\n",
        "    padding = \"same\", data_format = \"channels_last\", # input with shape (batch, height, width, channels)\n",
        "    activation = 'linear', # activation function to use\n",
        "    use_bias = True,\n",
        "    kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev = 1e-2), # initializer for the kernel weights matrix\n",
        "    bias_initializer = 'zeros', # initializer for the bias vector\n",
        "    input_shape = (240, 240, 155)\n",
        ")(input)\n",
        "network = tf.keras.layers.LeakyReLU(alpha = 0.2)(network)\n",
        "network = tf.keras.layers.BatchNormalization(\n",
        "    momentum = 0.1, # momentum + decay = 1.0\n",
        "    epsilon = 1e-5,\n",
        "    scale = True\n",
        ")(network)\n",
        "# layer 2\n",
        "network = tf.keras.layers.Conv2D(\n",
        "    filters = 64, # dimensionality of output space\n",
        "    kernel_size = 5, # shape of 2D convolution window (5x5)\n",
        "    strides = 1,\n",
        "    padding = \"same\", data_format = \"channels_last\",\n",
        "    activation = 'linear',\n",
        "    use_bias = True,\n",
        "    kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev = 1e-2),\n",
        "    bias_initializer = 'zeros',\n",
        "    input_shape = (240, 240, 128)\n",
        ")(network)\n",
        "network = tf.keras.layers.LeakyReLU(alpha = 0.2)(network)\n",
        "network = tf.keras.layers.BatchNormalization(\n",
        "    momentum = 0.1, # momentum + decay = 1.0\n",
        "    epsilon = 1e-5\n",
        ")(network)\n",
        "# layer 3\n",
        "network = tf.keras.layers.Conv2D(\n",
        "    filters = 32, # dimensionality of output space\n",
        "    kernel_size = 3, # shape of 2D convolution window (3x3)\n",
        "    strides = 1,\n",
        "    padding = \"same\", data_format = \"channels_last\",\n",
        "    activation = 'linear',\n",
        "    use_bias = True,\n",
        "    kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev = 1e-2),\n",
        "    bias_initializer = 'zeros',\n",
        "    input_shape = (240, 240, 64)\n",
        ")(network)\n",
        "network = tf.keras.layers.LeakyReLU(alpha = 0.2)(network)\n",
        "network = tf.keras.layers.BatchNormalization(\n",
        "    momentum = 0.1, # momentum + decay = 1.0\n",
        "    epsilon = 1e-5\n",
        ")(network)\n",
        "# layer 4\n",
        "network = tf.keras.layers.Conv2D(\n",
        "    filters = 16, # dimensionality of output space : 16 channels\n",
        "    kernel_size = 3, # shape of 2D convolution window (3x3)\n",
        "    strides = 1,\n",
        "    padding = \"same\", data_format = \"channels_last\",\n",
        "    activation = 'linear',\n",
        "    use_bias = True,\n",
        "    kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev = 1e-2),\n",
        "    bias_initializer = 'zeros',\n",
        "    input_shape = (240, 240, 32)\n",
        ")(network)\n",
        "network = tf.keras.layers.LeakyReLU(alpha = 0.2)(network)\n",
        "network = tf.keras.layers.BatchNormalization(\n",
        "    momentum = 0.1, # momentum + decay = 1.0\n",
        "    epsilon = 1e-5\n",
        ")(network)\n",
        "# layer 5\n",
        "network = tf.keras.layers.Conv2D(\n",
        "    filters = 1, # dimensionality of output space : 1 channel (grayscale/flatten)\n",
        "    kernel_size = 1, # shape of 2D convolution window (1x1)\n",
        "    strides = 1,\n",
        "    padding = \"same\", data_format = \"channels_last\",\n",
        "    activation = 'linear', #tf.keras.activations.tanh,\n",
        "    use_bias = True,\n",
        "    kernel_initializer = tf.keras.initializers.TruncatedNormal(stddev = 1e-2),\n",
        "    bias_initializer = 'zeros',\n",
        ")(network)\n",
        "\"\"\"\n",
        "# unet\n",
        "input = Input(shape=(optx,opty,optz))\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(input)\n",
        "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool1)\n",
        "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool2)\n",
        "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool3)\n",
        "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool4)\n",
        "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv5)\n",
        "\n",
        "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv5))\n",
        "merge6 = concatenate([conv4,up6], axis = 3)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge6)\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv6)\n",
        "\n",
        "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv6))\n",
        "merge7 = concatenate([conv3,up7], axis = 3)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge7)\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv7)\n",
        "\n",
        "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv7))\n",
        "merge8 = concatenate([conv2,up8], axis = 3)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge8)\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv8)\n",
        "\n",
        "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv8))\n",
        "merge9 = concatenate([conv1,up9], axis = 3)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge9)\n",
        "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv9)\n",
        "network = Conv2D(1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv9)\n",
        "\n",
        "# simplified unet\n",
        "input = Input(shape=(optx,opty,optz)) # infer size at runtime from cropped volumes\n",
        "\n",
        "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(input)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool2)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool3)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool4)\n",
        "\n",
        "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv5))\n",
        "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(up6)\n",
        "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv6))\n",
        "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(up7)\n",
        "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv7))\n",
        "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(up8)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# unet\\ninput = Input(shape=(optx,opty,optz))\\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(input)\\nconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv1)\\npool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool1)\\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv2)\\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool2)\\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv3)\\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool3)\\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv4)\\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\\n\\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool4)\\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv5)\\n\\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv5))\\nmerge6 = concatenate([conv4,up6], axis = 3)\\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge6)\\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv6)\\n\\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv6))\\nmerge7 = concatenate([conv3,up7], axis = 3)\\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge7)\\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv7)\\n\\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv7))\\nmerge8 = concatenate([conv2,up8], axis = 3)\\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge8)\\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv8)\\n\\nup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv8))\\nmerge9 = concatenate([conv1,up9], axis = 3)\\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(merge9)\\nconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv9)\\nnetwork = Conv2D(1, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(conv9)\\n\\n# simplified unet\\ninput = Input(shape=(optx,opty,optz)) # infer size at runtime from cropped volumes\\n\\nconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(input)\\npool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\\nconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool2)\\npool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\\nconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool3)\\npool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\\n\\nconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(pool4)\\n\\nup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv5))\\nconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(up6)\\nup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv6))\\nconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(up7)\\nup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(UpSampling2D(size = (2,2))(conv7))\\nconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal', data_format = 'channels_last')(up8)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bm5VkRhRbjn",
        "colab_type": "code",
        "outputId": "b623ed58-09c9-42a9-c607-3714bf3d0362",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "print(\"DEFINING MODEL\")\n",
        "model = tf.keras.Model(inputs = input, outputs = network)\n",
        "#model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002), loss = loss_binary_crossentropy_unsupervised, metrics = ['accuracy'])\n",
        "model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002), loss = loss_ssim_unsupervised, metrics = ['accuracy'])\n",
        "#model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.002), loss = loss_ssim_supervised_nsst, metrics = ['accuracy'])\n",
        "\n",
        "checkpoint_path = base_path + \"checkpoints/checkpoint-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
        "latest = tf.train.latest_checkpoint(base_path + \"checkpoints\")\n",
        "if(latest == None):\n",
        "    print(\"No checkpoints\")\n",
        "else:\n",
        "    print(\"Loading latest checkpoint\")\n",
        "    #model.load_weights(latest)\n",
        "model.summary(line_length=100)\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, to_file='model_unet.png')\n",
        "\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=base_path + 'logs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEFINING MODEL\n",
            "Loading latest checkpoint\n",
            "Model: \"model_5\"\n",
            "____________________________________________________________________________________________________\n",
            "Layer (type)                                 Output Shape                            Param #        \n",
            "====================================================================================================\n",
            "input_3 (InputLayer)                         [(None, 240, 240, 155)]                 0              \n",
            "____________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)                           (None, 240, 240, 128)                   496128         \n",
            "____________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)                    (None, 240, 240, 128)                   0              \n",
            "____________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNormalization)   (None, 240, 240, 128)                   512            \n",
            "____________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)                           (None, 240, 240, 64)                    204864         \n",
            "____________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)                    (None, 240, 240, 64)                    0              \n",
            "____________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNormalization)   (None, 240, 240, 64)                    256            \n",
            "____________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)                           (None, 240, 240, 32)                    18464          \n",
            "____________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)                    (None, 240, 240, 32)                    0              \n",
            "____________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNormalization)   (None, 240, 240, 32)                    128            \n",
            "____________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)                           (None, 240, 240, 16)                    4624           \n",
            "____________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)                    (None, 240, 240, 16)                    0              \n",
            "____________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNormalization)   (None, 240, 240, 16)                    64             \n",
            "____________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)                           (None, 240, 240, 1)                     17             \n",
            "====================================================================================================\n",
            "Total params: 725,057\n",
            "Trainable params: 724,577\n",
            "Non-trainable params: 480\n",
            "____________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHuz35FR7IJN",
        "colab_type": "code",
        "outputId": "8d5959c5-ca85-4039-d9f3-ea48cc15c9dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "print(\"STARTING TRAINING PHASE\")\n",
        "# train\n",
        "history_fit = model.fit(cropped_padded_train_volumes_mri, cropped_padded_train_volumes_mri, epochs = epoch, batch_size = batch_size, callbacks = [cp_callback])\n",
        "#history_fit = model.fit(train_volumes_mri, train_images_groundtruth, epochs = epoch, batch_size = batch_size, callbacks = [cp_callback, tb_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING TRAINING PHASE\n",
            "Train on 5 samples\n",
            "Epoch 1/3\n",
            "4/5 [=======================>......] - ETA: 2s - loss: 13.4947 - accuracy: 0.9400\n",
            "Epoch 00001: saving model to /content/drive/My Drive/Colab Notebooks/checkpoints/checkpoint-0001.ckpt\n",
            "5/5 [==============================] - 13s 3s/sample - loss: 15.2135 - accuracy: 0.9308\n",
            "Epoch 2/3\n",
            "4/5 [=======================>......] - ETA: 1s - loss: 13.4946 - accuracy: 0.9400\n",
            "Epoch 00002: saving model to /content/drive/My Drive/Colab Notebooks/checkpoints/checkpoint-0002.ckpt\n",
            "5/5 [==============================] - 10s 2s/sample - loss: 15.2134 - accuracy: 0.9308\n",
            "Epoch 3/3\n",
            "4/5 [=======================>......] - ETA: 1s - loss: 15.0204 - accuracy: 0.9306\n",
            "Epoch 00003: saving model to /content/drive/My Drive/Colab Notebooks/checkpoints/checkpoint-0003.ckpt\n",
            "5/5 [==============================] - 9s 2s/sample - loss: 15.2134 - accuracy: 0.9308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsKixiKgEfna",
        "colab_type": "code",
        "outputId": "0052e66e-7ff0-4f73-fa71-455e64ec9fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(\"STARTING TESTING PHASE\")\n",
        "show_information(test_volumes_mri)\n",
        "history_eval = model.evaluate(cropped_padded_test_volumes_mri, cropped_padded_test_volumes_mri, batch_size = batch_size)\n",
        "#history_eval = model.evaluate(test_volumes_mri, test_images_groundtruth, batch_size = batch_size)\n",
        "\n",
        "# get results\n",
        "predictions = model.predict(cropped_padded_test_volumes_mri, batch_size = 1, verbose = 1)\n",
        "print(\"max pixel value:\", tf.reduce_max(predictions))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTING TESTING PHASE\n",
            "Tensor Shape: [2 240 240 155]\n",
            "Shape: TensorShape([2, 240, 240, 155])\n",
            "Mean: 0.00362583483\n",
            "Min: 0\n",
            "Max: 0.933266938\n",
            "2/1 [============================================================] - 2s 933ms/sample - loss: 10.6668 - accuracy: 0.9617\n",
            "2/1 [============================================================] - 0s 199ms/sample\n",
            "max pixel value: tf.Tensor(0.0, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE2-_0hQZ_iW",
        "colab_type": "code",
        "outputId": "a394af03-6986-4aea-e5c7-18b57c56bca2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "tf.print(\"predictions\")\n",
        "show_information(predictions)\n",
        "tf.print(\"\\ntrain-groundtruth\")\n",
        "show_information(train_images_groundtruth)\n",
        "tf.print(\"\\ntest-groundtruth\")\n",
        "show_information(test_images_groundtruth)\n",
        "tf.print(\"\\ntrain-dataset\")\n",
        "show_information(train_volumes_mri)\n",
        "tf.print(\"\\ntest-dataset\")\n",
        "show_information(test_volumes_mri)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions\n",
            "Tensor Shape: [2 128 128 1]\n",
            "Shape: (2, 128, 128, 1)\n",
            "Mean: 0\n",
            "Min: 0\n",
            "Max: 0\n",
            "\n",
            "train-groundtruth\n",
            "Tensor Shape: [100 240 240 1]\n",
            "Shape: TensorShape([100, 240, 240, 1])\n",
            "Mean: 0.0122436183\n",
            "Min: 0\n",
            "Max: 1\n",
            "\n",
            "test-groundtruth\n",
            "Tensor Shape: [2 240 240 1]\n",
            "Shape: TensorShape([2, 240, 240, 1])\n",
            "Mean: 0.00887712091\n",
            "Min: 0\n",
            "Max: 1\n",
            "\n",
            "train-dataset\n",
            "Tensor Shape: [5 240 240 155]\n",
            "Shape: TensorShape([5, 240, 240, 155])\n",
            "Mean: 0.00534980558\n",
            "Min: 0\n",
            "Max: 0.775265932\n",
            "\n",
            "test-dataset\n",
            "Tensor Shape: [2 240 240 155]\n",
            "Shape: TensorShape([2, 240, 240, 155])\n",
            "Mean: 0.00362583483\n",
            "Min: 0\n",
            "Max: 0.933266938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HWpM_vtmWus",
        "colab_type": "code",
        "outputId": "7ff27a2c-8f18-4868-9688-706bdde733e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "show_volume(test_volumes_mri[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor Shape: [240 240 155]\n",
            "Shape: TensorShape([240, 240, 155])\n",
            "Mean: 0.00551973283\n",
            "Min: 0\n",
            "Max: 0.933266938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9cfcdc096cc4fafa86ae24b758c6733",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "interactive(children=(IntSlider(value=0, description='x', max=154), Output()), _dom_classes=('widget-interact'…"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTNx9MqNYfis",
        "colab_type": "code",
        "outputId": "f30827e7-e43b-4b11-8c9a-13d19ad25d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "i=0\n",
        "for pred in predictions:\n",
        "    img = tf.image.convert_image_dtype(pred, tf.uint8)\n",
        "    plt.imshow(tf.tile(img, (1,1,3)))\n",
        "    img = tf.image.encode_png(img)\n",
        "    name = base_path + 'pred/linear_lr0.002-normalize-cropped-ssim_unsupervised' + str(i) + '.png'\n",
        "    tf.io.write_file(name, img)\n",
        "    i = i + 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUkNQ0FSw1CQ1DAUJDX+F+x3jFrKCx/XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN0v50bYxSuz",
        "colab_type": "code",
        "outputId": "40ac9f3e-57dd-42ec-bad6-6ce56c47932f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "from keract import get_activations,display_activations,display_heatmaps,get_gradients_of_trainable_weights,get_gradients_of_activations\n",
        "\n",
        "input_image=cropped_padded_test_volumes_mri[0]\n",
        "input_image = np.expand_dims(input_image, axis=-1)\n",
        "activations = get_activations(model, input_image)\n",
        "display_activations(activations, cmap=\"gray\", save=True)\n",
        "display_heatmaps(activations, input_image, save=True)\n",
        "get_gradients_of_trainable_weights(model, input_image, images_groundtruth)\n",
        "get_gradients_of_activations(model, input_image, images_groundtruth)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keract/keract.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(model, nodes_to_evaluate, x, y)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_inputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_targets\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_sample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keract/keract.py\u001b[0m in \u001b[0;36meval_fn\u001b[0;34m(k_inputs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_to_evaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_5 to have shape (128.0, 128.0, 128.0) but got array with shape (128, 128, 1)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-c8f9001b20ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcropped_padded_test_volumes_mri\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minput_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdisplay_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdisplay_heatmaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keract/keract.py\u001b[0m in \u001b[0;36mget_activations\u001b[0;34m(model, x, layer_name)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0minput_layer_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0minput_layer_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'input_'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m     \u001b[0mactivations_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mactivations_inputs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_layer_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keract/keract.py\u001b[0m in \u001b[0;36m_evaluate\u001b[0;34m(model, nodes_to_evaluate, x, y)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_inputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_targets\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_sample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keract/keract.py\u001b[0m in \u001b[0;36meval_fn\u001b[0;34m(k_inputs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes_to_evaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2472\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    572\u001b[0m                              \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                              str(data_shape))\n\u001b[0m\u001b[1;32m    575\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_5 to have shape (128.0, 128.0, 128.0) but got array with shape (128, 128, 1)"
          ]
        }
      ]
    }
  ]
}